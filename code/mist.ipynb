{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef4ea8f4355b426d9ff4180d90bc77b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78a1fe4fbc9140a3adae7383ad2cf7ed",
              "IPY_MODEL_f08eb52e585c46a7a9421ad7274cefcf",
              "IPY_MODEL_2a3e2fa6357a4eb4ac32c1bfef8e7120"
            ],
            "layout": "IPY_MODEL_7dd1c7c0bd4a49739d885b1cea342695"
          }
        },
        "78a1fe4fbc9140a3adae7383ad2cf7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62af0043cede41a096e83bbe97637cff",
            "placeholder": "​",
            "style": "IPY_MODEL_8af097694bdf4270a32ab0b2c4fc12ed",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f08eb52e585c46a7a9421ad7274cefcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8eb80f012814e7f93903dd7c2ed88ef",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_effabd8c6c014c3abdcd4cf0792cd4d7",
            "value": 4
          }
        },
        "2a3e2fa6357a4eb4ac32c1bfef8e7120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_311a5239309c4738bb96b78627c637b8",
            "placeholder": "​",
            "style": "IPY_MODEL_380675d4fd7543cbaabd35e4118223a7",
            "value": " 4/4 [01:16&lt;00:00, 16.75s/it]"
          }
        },
        "7dd1c7c0bd4a49739d885b1cea342695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62af0043cede41a096e83bbe97637cff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8af097694bdf4270a32ab0b2c4fc12ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8eb80f012814e7f93903dd7c2ed88ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "effabd8c6c014c3abdcd4cf0792cd4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "311a5239309c4738bb96b78627c637b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "380675d4fd7543cbaabd35e4118223a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unstructured[all-docs]\""
      ],
      "metadata": {
        "id": "vYUzjmVgoMyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "tMxzcHl2oUpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate sentence-transformers bitsandbytes chromadb docx2txt"
      ],
      "metadata": {
        "id": "KbcVm7RvoM1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "4xKCKdGTuzLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "jEIFHxGdoM4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tesseract\n",
        "!pip install pytesseract\n",
        "!apt-get install poppler-utils\n",
        "!pip install langchain-community\n",
        "!pip install sentence-transformers\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "nIKhV-yloNEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask_cors\n",
        "!pip install reportlab"
      ],
      "metadata": {
        "id": "MwWX35Skv3tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "!pip install Flask"
      ],
      "metadata": {
        "id": "8Bd7g4RZg4Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "metadata": {
        "id": "ntqefuyoorh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import UnstructuredPDFLoader ,UnstructuredCSVLoader\n",
        "from langchain_community.document_loaders import UnstructuredWordDocumentLoader\n",
        "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
        "from langchain_community.document_loaders.image import UnstructuredImageLoader\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader"
      ],
      "metadata": {
        "id": "0N-j4cIho5YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline , BitsAndBytesConfig\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.text_splitter import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "obzoexVntOY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.merge import MergedDataLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Chroma\n",
        "import transformers"
      ],
      "metadata": {
        "id": "fcK0stbbtawE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "CVbtJg2ZvXLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ2ws77Jo5bU",
        "outputId": "c87460a7-a3c4-410a-fa90-0d08b8903a87"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "2LrRK0mkar0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317948a1-2d57-48f8-f816-a0cf50f27121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Data_ingetion(file_path):\n",
        "  document = []\n",
        "  for file in os.listdir(file_path):\n",
        "    if file.endswith(\".pdf\"):\n",
        "      pdf_path=file_path+\"/\"+file\n",
        "      loader=UnstructuredPDFLoader(pdf_path)\n",
        "      document.extend(loader.load())\n",
        "    elif file.endswith('.docx') or file.endswith('.docs'):\n",
        "      doc_path=file_path+\"/\"+file\n",
        "      loader=UnstructuredWordDocumentLoader(doc_path)\n",
        "      document.extend(loader.load())\n",
        "    elif file.endswith('.jpg'):\n",
        "      text_path=file_path+\"/\"+file\n",
        "      loader=UnstructuredImageLoader(text_path)\n",
        "      document.extend(loader.load())\n",
        "    elif file.endswith('.xlsx'):\n",
        "      text_path=file_path+\"/\"+file\n",
        "      loader=UnstructuredExcelLoader(text_path)\n",
        "      document.extend(loader.load())\n",
        "    elif file.endswith('.csv'):\n",
        "      text_path=file_path+\"/\"+file\n",
        "      loader=UnstructuredCSVLoader(text_path)\n",
        "      document.extend(loader.load())\n",
        "    elif file.endswith('.jpeg'):\n",
        "      text_path=file_path+\"/\"+file\n",
        "      loader=UnstructuredImageLoader(text_path)\n",
        "      document.extend(loader.load())\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  return document\n",
        "\n",
        "\n",
        "def vector_store(document):\n",
        "  document_splitter=CharacterTextSplitter(separator='}', chunk_size=7000, chunk_overlap=100)\n",
        "  document_chunks=document_splitter.split_documents(document)\n",
        "  vectordb=Chroma.from_documents(document,embedding=embeddings, persist_directory='./datas')\n",
        "  parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
        "  child_splitter = RecursiveCharacterTextSplitter(chunk_size=300)\n",
        "  vectorstore = Chroma(collection_name=\"split_parents\", embedding_function=embeddings,persist_directory='./datas')\n",
        "  store = InMemoryStore()\n",
        "\n",
        "  big_chunks_retriever = ParentDocumentRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        "    parent_splitter=parent_splitter,\n",
        "  )\n",
        "  big_chunks_retriever.add_documents(document_chunks)\n",
        "\n",
        "  return big_chunks_retriever\n",
        "\n"
      ],
      "metadata": {
        "id": "RQTpaovvP6V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "<|start_header_id|>user<|end_header_id|>\n",
        "You are an assistant for answering questions about RAG.\n",
        "You are given the extracted parts of a long document and a question. Provide a conversational answer.\n",
        "If you don't know the answer, just say \"I do not know.\" Don't make up an answer.\n",
        "\n",
        "Question: {question}\n",
        "Context: {context}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=prompt_template,\n",
        ")"
      ],
      "metadata": {
        "id": "fcI0CihRl2zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if User Question ask Answer in table format than you give detail in table_header and table_detail,\\n\n",
        "# where table_header have table header like colume name and table_detail all the detail of table like rows but in json format .\n",
        "# Question:Give me RBC count of harsh.\n",
        "\n",
        "# Answer: 9.3mill\n",
        "\n",
        "# Question:Give me Top 5 country currency in json format and in form of table headers and table details.\n",
        "# Answer:{\n",
        "#   \"table_headers\": [\"Currency Name\", \"Country\", \"Symbol\", \"Code\", \"Exchange Rate\"],\n",
        "#   \"table_details\": [\n",
        "#     [\"US Dollar\", \"United States\", \"$\", \"USD\", \"1.00\"],\n",
        "#     [\"Euro\", \"European Union\", \"€\", \"EUR\", \"0.84\"],\n",
        "#     [\"Japanese Yen\", \"Japan\", \"¥\", \"JPY\", \"110.62\"],\n",
        "#     [\"British Pound\", \"United Kingdom\", \"£\", \"GBP\", \"0.72\"],\n",
        "#     [\"Swiss Franc\", \"Switzerland\", \"CHF\", \"1.08\"]\n",
        "#   ]\n",
        "# }"
      ],
      "metadata": {
        "id": "H0s5qsXTtWP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "4E36k7S9Uktj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = Data_ingetion(\"/content/drive/MyDrive/policy\")\n",
        "retriever = vector_store(docs)\n",
        "retriever"
      ],
      "metadata": {
        "id": "cpgeZwZ_nUsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "device_map = \"auto\"\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                                          bnb_4bit_quant_type=\"nf4\",\n",
        "                                          bnb_4bit_use_double_quant=True,\n",
        "                                          bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                                          )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                            quantization_config=quantization_config,\n",
        "                                            device_map=\"auto\",\n",
        "                                            low_cpu_mem_usage = True,\n",
        "                                          #  torch_dtype = torch.bfloat16,\n",
        "                                          # use_auth_token = False,\n",
        "                                            #load_in_4bit = True,\n",
        "                                            )\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name,)\n",
        "                                          # use_auth_token=False)\n",
        "terminators = [\n",
        "  tokenizer.eos_token_id,\n",
        "  tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "  ]\n",
        "\n",
        "text_generation_pipeline = pipeline(\n",
        "  model=model,\n",
        "  tokenizer=tokenizer,\n",
        "  task=\"text-generation\",\n",
        "  temperature=0.2,\n",
        "  do_sample=True,\n",
        "  repetition_penalty=1.1,\n",
        "  return_full_text=False,\n",
        "  max_new_tokens=200,\n",
        "  eos_token_id=terminators,\n",
        "  )\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ef4ea8f4355b426d9ff4180d90bc77b8",
            "78a1fe4fbc9140a3adae7383ad2cf7ed",
            "f08eb52e585c46a7a9421ad7274cefcf",
            "2a3e2fa6357a4eb4ac32c1bfef8e7120",
            "7dd1c7c0bd4a49739d885b1cea342695",
            "62af0043cede41a096e83bbe97637cff",
            "8af097694bdf4270a32ab0b2c4fc12ed",
            "b8eb80f012814e7f93903dd7c2ed88ef",
            "effabd8c6c014c3abdcd4cf0792cd4d7",
            "311a5239309c4738bb96b78627c637b8",
            "380675d4fd7543cbaabd35e4118223a7"
          ]
        },
        "id": "iVBVZDQzluY3",
        "outputId": "14d20dfb-e5c3-41df-e926-c8cc1647ca3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef4ea8f4355b426d9ff4180d90bc77b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                   chain_type_kwargs={\"prompt\": prompt},\n",
        "                                             retriever= retriever,    #vectordb.as_retriever(search_kwargs={'k':2}),\n",
        "                                             verbose=False)\n"
      ],
      "metadata": {
        "id": "vPjXaShKehKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True :\n",
        "  qu = input()\n",
        "  if qu == \"exit\":\n",
        "    break\n",
        "  else:\n",
        "    results = query(qu)\n",
        "    extract = results['result']\n",
        "    ans = extract.rsplit('[/INST]',1)[-1].strip()\n",
        "    print(ans)"
      ],
      "metadata": {
        "id": "rvQ_-20Cg5kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask , jsonify ,render_template, request ,send_file\n",
        "import requests\n",
        "from pyngrok import ngrok\n",
        "from flask_cors import CORS\n",
        "import re"
      ],
      "metadata": {
        "id": "DhZJpXrW4JRL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "file_path = '/content/drive/MyDrive/policy/chat_history.json'\n",
        "def append_question_answer(question, answer, file_path):\n",
        "\n",
        "    data = []\n",
        "    if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
        "        with open(file_path, \"r\") as json_file:\n",
        "            data = json.load(json_file)\n",
        "    data.append({\n",
        "        \"question\": question,\n",
        "        \"answer\": answer\n",
        "    })\n",
        "    with open(file_path, \"w\") as json_file:\n",
        "        json.dump(data, json_file, indent=2)"
      ],
      "metadata": {
        "id": "MTI3dqT2mO-2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "from reportlab.lib import colors\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph ,Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet ,ParagraphStyle\n",
        "\n",
        "def create_pdf(file_path):\n",
        "    # Create a PDF document\n",
        "    pdf_filename = \"output.pdf\"\n",
        "    doc = SimpleDocTemplate(pdf_filename, pagesize=letter)\n",
        "\n",
        "    # Define styles for the table\n",
        "    style_table = TableStyle([('BACKGROUND', (0, 0), (-1, 0), colors.lightgrey),\n",
        "                              ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),\n",
        "                              ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
        "                              ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
        "                              ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
        "                              ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
        "                              ('GRID', (0, 0), (-1, -1), 1, colors.black)])\n",
        "\n",
        "    # Define styles for the text\n",
        "    #style_text = getSampleStyleSheet()[\"Normal\"]\n",
        "    # Define styles for the text\n",
        "    style_text = ParagraphStyle(name='Text', fontSize=10)\n",
        "\n",
        "    # Define styles for the questions\n",
        "    style_question = ParagraphStyle(name='Question', fontSize=12, )#textColor=colors.blue)\n",
        "\n",
        "    # Create a list to hold the content for the PDF\n",
        "    elements = []\n",
        "    with open(file_path, \"r\") as json_file:\n",
        "      data = json.load(json_file)\n",
        "    # Iterate over each item in the data\n",
        "    for item in data:\n",
        "        question = item['question']\n",
        "        answer = item['answer']\n",
        "\n",
        "        # Add question as a heading\n",
        "        elements.append(Paragraph(\"Question: \"+question, style_question))\n",
        "\n",
        "        # Check if the answer is in tabular format\n",
        "        try:\n",
        "            answer_dict = ast.literal_eval(answer)\n",
        "            if isinstance(answer_dict, dict) and 'table_headers' in answer_dict and 'table_details' in answer_dict:\n",
        "                # Answer is in tabular format\n",
        "                headers = answer_dict['table_headers']\n",
        "                details = answer_dict['table_details']\n",
        "\n",
        "                # Create a table\n",
        "                table_data = [headers] + details\n",
        "                table = Table(table_data)\n",
        "\n",
        "                # Apply styles to the table\n",
        "                table.setStyle(style_table)\n",
        "\n",
        "                # Add table to the PDF\n",
        "                elements.append(table)\n",
        "            else:\n",
        "                # Answer is not in tabular format, add as text\n",
        "                elements.append(Paragraph(\"Answer: \"+answer, style_text))\n",
        "        except (SyntaxError, ValueError):\n",
        "            # Answer is not in tabular format, add as text\n",
        "            elements.append(Paragraph(\"Answer: \"+answer, style_text))\n",
        "        elements.append(Spacer(1, 20))\n",
        "    # Build PDF document\n",
        "    doc.build(elements)\n",
        "\n",
        "# Create PDF\n",
        "file_path = '/content/drive/MyDrive/policy/chat_history.json'\n",
        "create_pdf(file_path)\n"
      ],
      "metadata": {
        "id": "kN5e_Iggq6ho"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__) #template_folder=\"/content/templates\")\n",
        "ngrok.set_auth_token('2ewXWmHQlnn9apwWj3X0A6r3lFi_TbVgKWhGFqhT46PzckbU')\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "CORS(app,resources={r\"/ask\"})\n",
        "\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return \"<h1>GFG is great platform to learn</h1>\"\n",
        "\n",
        "\n",
        "@app.route(\"/ask\", methods=['POST'])\n",
        "def ask():\n",
        "    text = request.get_data(as_text=True)\n",
        "    if \"table\" in text.lower():\n",
        "      output_string = re.sub(r'\\btable\\b', 'json', text)\n",
        "      extract = query(output_string )#+ \" and Only Give table_headers and table details in list [do not use '\\n'] and any other text\")\n",
        "      extract = extract['result']\n",
        "      append_question_answer(text, extract,file_path)\n",
        "      print(extract)\n",
        "    else:\n",
        "      bot_response = query(text)\n",
        "      extract = str(bot_response['result'])\n",
        "      append_question_answer(text, extract,file_path)\n",
        "      print(extract)\n",
        "    return jsonify({'status':'OK','answer':extract})\n",
        "    # return jsonify({'status':'OK','answer':bot_response.content})\n",
        "\n",
        "\n",
        "@app.route('/generate_pdf')\n",
        "def generate_pdf():\n",
        "    file_path = create_pdf('/content/drive/MyDrive/policy/chat_history.json')  # Adjust the path accordingly\n",
        "    return send_file(file_path, as_attachment=True)\n",
        "\n",
        "# Route to handle file sending\n",
        "# @app.route('/get-file/<filename>')\n",
        "# def get_file(filename):\n",
        "#     # Replace 'uploads' with the directory where your files are stored\n",
        "#     file_path = f'uploads/{filename}'\n",
        "#     try:\n",
        "#         return send_file(file_path, as_attachment=True)\n",
        "#     except FileNotFoundError:\n",
        "#         return \"File not found\", 404\n",
        "\n",
        "\n",
        "print(f\"To access the Gloable link please click {public_url}\")\n",
        "app.run(port=5000)"
      ],
      "metadata": {
        "id": "S2Uz8kq24JUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd93a376-ef62-484e-d89e-549d71abc479"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To access the Gloable link please click https://c7b8-34-168-123-199.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "ERROR:__main__:Exception on /generate_pdf [GET]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 2529, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1825, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask_cors/extension.py\", line 176, in wrapped_function\n",
            "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1823, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1799, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
            "  File \"<ipython-input-11-34a0c4ad8d14>\", line 33, in generate_pdf\n",
            "    return send_file(file_path, as_attachment=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/helpers.py\", line 537, in send_file\n",
            "    return werkzeug.utils.send_file(  # type: ignore[return-value]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/werkzeug/utils.py\", line 438, in send_file\n",
            "    raise TypeError(\n",
            "TypeError: Unable to detect the MIME type because a file name is not available. Either set 'download_name', pass a path instead of a file, or set 'mimetype'.\n",
            "INFO:werkzeug:127.0.0.1 - - [02/May/2024 06:15:13] \"\u001b[35m\u001b[1mGET /generate_pdf HTTP/1.1\u001b[0m\" 500 -\n",
            "INFO:werkzeug:127.0.0.1 - - [02/May/2024 06:15:13] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "ERROR:__main__:Exception on /generate_pdf [GET]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 2529, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1825, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask_cors/extension.py\", line 176, in wrapped_function\n",
            "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1823, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1799, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
            "  File \"<ipython-input-11-34a0c4ad8d14>\", line 33, in generate_pdf\n",
            "    return send_file(file_path, as_attachment=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/helpers.py\", line 537, in send_file\n",
            "    return werkzeug.utils.send_file(  # type: ignore[return-value]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/werkzeug/utils.py\", line 438, in send_file\n",
            "    raise TypeError(\n",
            "TypeError: Unable to detect the MIME type because a file name is not available. Either set 'download_name', pass a path instead of a file, or set 'mimetype'.\n",
            "INFO:werkzeug:127.0.0.1 - - [02/May/2024 06:15:21] \"\u001b[35m\u001b[1mGET /generate_pdf HTTP/1.1\u001b[0m\" 500 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(file_path, \"r\") as json_file:\n",
        "    data = json.load(json_file)\n",
        "    print(data)"
      ],
      "metadata": {
        "id": "ecUvAYLM4Jeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794450b4-9f96-4a9b-dffa-1eeec91371e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'question': '\"Give me Address and email of Yagnya Deshpande in table format?\"', 'answer': 'Here is the answer to your question:\\n\\n**Table Headers**\\n```\\n{\\n\"Name\": \"\",\\n\"Email\": \"\"\\n}\\n```\\n\\n**Table Details**\\n```\\n[\\n{\\n\"Name\": \"Miss. Yagnya Deshpande\",\\n\"Email\": \"pawarhospitalpvtltd@gmail.com\"\\n},\\n{\\n\"Name\": \"Dr. Manish Gaikwad\",\\n\"Email\": \"pawarhospitalpvtltd@gmail.com\"\\n},\\n{\\n\"Name\": \"Suraj Hospital\",\\n\"Email\": \"spirehospitalpune@gmail.com\"\\n}\\n]\\n```\\n\\nPlease note that there are multiple addresses and emails mentioned in the provided documents, so I\\'ve included them all in the response. Let me know if you need further assistance!'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "-i-XQ09MrYVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_all_data(file_path):\n",
        "    # Write an empty list to the file\n",
        "    with open(file_path, \"w\") as json_file:\n",
        "        json.dump([], json_file)\n",
        "\n",
        "    print(\"All data deleted successfully!\")\n",
        "\n",
        "delete_all_data(file_path)"
      ],
      "metadata": {
        "id": "oi84dc_KmyCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b88fed-2b0b-439a-c5a5-1fd5458d0170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All data deleted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_question(question):\n",
        "    for item in data:\n",
        "        if item['question'] == question:\n",
        "            data.remove(item)\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Example: Remove a question\n",
        "question_to_remove = 'top 5 county curreny in table format'\n",
        "if remove_question(question_to_remove):\n",
        "    print(f\"Question '{question_to_remove}' removed successfully.\")\n",
        "else:\n",
        "    print(f\"Question '{question_to_remove}' not found in the data.\")\n",
        "\n",
        "# Output the updated data\n",
        "print(json.dumps(data, indent=2))"
      ],
      "metadata": {
        "id": "St5-3Eo7q6tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GgIbsTI_HFJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JjUpX_Zrt58y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "391YfqNl22d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEaQr5ba22gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ioqd3jPy22j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                             quantization_config=bnb_config,\n",
        "                                             device_map=\"auto\",\n",
        "                                             low_cpu_mem_usage = True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from transformers import pipeline\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "text_generation_pipeline = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    temperature=0.2,\n",
        "    do_sample=True,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=200,\n",
        "    eos_token_id=terminators,\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n"
      ],
      "metadata": {
        "id": "IwjFjNL-FyW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3GQvYtwM3Nl"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"\n",
        "<|begin_of_text|>\n",
        "<|start_header_id|>system<|end_header_id|>\n",
        "You are Document Expert AI who Know how find Answer from document which present in Vecter store and give Exect Answer of question.\n",
        "Given the following conversation and a follow up question,\n",
        "rephrase the follow up question to be a standalone question, in its original language,\n",
        "if the answer is not in provided context just say, \" Enter a valid Question \", don't provide the wrong answer.\n",
        "that can be used to query a chromadb. This query will be used to retrieve documents with additional context.\n",
        "Do not provided extra information from the Document\n",
        "Let me share a couple examples.\n",
        "<|eot_id|>\n",
        "\n",
        "<|start_header_id|>user<|end_header_id|>\n",
        "what is gmail id of Harsh ?\n",
        "<|eot_id|>\n",
        "<|start_header_id|>assistant<|end_header_id|>\n",
        "hsinghharsh123@gmail.com\n",
        "<|eot_id|>\n",
        "\n",
        "<|start_header_id|>user<|end_header_id|>\n",
        "what is policy no. or policy number of Harsh singh?\n",
        "<|eot_id|>\n",
        "\n",
        "<|start_header_id|>assistant<|end_header_id|>\n",
        "92000037890400000107\n",
        "<|eot_id|>\n",
        "\n",
        "<|start_header_id|>user<|end_header_id|>\n",
        "what is Hospital name where health claim?\n",
        "<|eot_id|>\n",
        "\n",
        "<|start_header_id|>assistant<|end_header_id|>\n",
        "Suraj Hospital\n",
        "<|eot_id|>\n",
        "\n",
        "<|start_header_id|>user<|end_header_id|>\n",
        "what is phone number or mobile number of Harsh ?\n",
        "<|eot_id|>\n",
        "<|start_header_id|>assistant<|end_header_id|>\n",
        "626575425\n",
        "<|eot_id|>\n",
        "\n",
        "<|start_header_id|>user<|end_header_id|>\n",
        "what is skills of Harsh singh?\n",
        "<|eot_id|>\n",
        "<|start_header_id|>assistant<|end_header_id|>\n",
        "NumPy, Object Oriented Programming, SQL, HTML, PyCharm, Jupyter Notebook, VS code, Git and GitHub, JIRA\n",
        "<|eot_id|>\n",
        "\n",
        "Question: {question}\n",
        "Context: {context}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template = prompt_template,input_variables=[\"context\", \"question\"],)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question = \"What is RBC count of miss yagnya deshpande?\"\n",
        "# rag_chain.invoke(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "g_GlKNa8FyzH",
        "outputId": "55a7ae4c-19b4-4bdf-b59e-79e58e90ce7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Based on the provided report, I can see that the patient's name is Miss Yagnya Deshpande, and the report is from Pawar Multispeciality Hospital & Diagnostic Centre Pvt. Ltd.\\n\\nAccording to the report, the RBC count is mentioned as 2.8 mil./Cmm, which falls within the reference range of 4.5 -6.5 mil./Cmm.\\n\\nSo, the answer to your question is: The RBC count of Miss Yagnya Deshpande is 2.8 mil./Cmm.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                   chain_type_kwargs={\"prompt\": prompt},\n",
        "                                    chain_type=\"stuff\",\n",
        "                                             retriever= retriever,    #vectordb.as_retriever(search_kwargs={'k':2}),\n",
        "                                             verbose=False)"
      ],
      "metadata": {
        "id": "w7IdEFinFy1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query(\"Give me Total Amount of miss Yagnya deshpande ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oy8q78qOrjP",
        "outputId": "e592f1aa-fcf5-45c7-90db-8ea6d2208d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Give me Total Amount of miss Yagnya deshpande ?',\n",
              " 'result': \"The total amount of Miss Yagnya Deshpande's bill is ₹ 31755.00.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gh =query(\"Give me detail of this name is yagnya and policy no. 92000034230400000103 ?\")\n",
        "gh['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "2em7odTPQUpY",
        "outputId": "099b7d34-a809-4c85-a1ef-00f1edc6c83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the provided context and extracted parts of the document, I can try to answer your question.\\n\\nThe question is: \"Give me detail of this name is yagnya and policy no. 92000034230400000103?\"\\n\\nFrom the given information, we can see that the name is Yagnya, and she is a 22-year-old female who has taken out a health insurance policy with policy number 92000034230400000103. The policy was started on June 1, 2023, and the claimant is seeking cashless hospitalization for her illness, which is diagnosed as acute diarrhea and gastroenteritis of presumed infectious origin.\\n\\nThe relevant clinical findings mentioned in the report include:\\n\\n* Haemoglobin level: 9.3 gm%\\n* Total WBC Count: 5100 /Cmm\\n* RBC count: 2.8 mil./Cmm\\n* Differential Neutrophils: 64%\\n* Lymphocytes: '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True :\n",
        "  qu = input()\n",
        "  if qu == \"exit\":\n",
        "    break\n",
        "  else:\n",
        "    results = query(qu)\n",
        "    # extract = results['result']\n",
        "    # ans = extract.rsplit('[/INST]',1)[-1].strip()\n",
        "    print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "KnZwdewoFy4W",
        "outputId": "ad163185-1033-45e8-8733-7af3c86a0398"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what is RBC count of miss yagnya deshpande?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query': 'what is RBC count of miss yagnya deshpande?', 'result': 'Hi there!\\n\\nAccording to the report, the RBC (Red Blood Cell) count of Miss Yagnya Deshpande is 2.8 million per cubic millimeter (mil./Cmm), which falls within the reference range of 4.5-6.5 mil./Cmm.\\n\\nLet me know if you have any further questions!'}\n",
            "What is the policy number of yagnya ?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query': 'What is the policy number of yagnya ?', 'result': \"I've searched through the provided context and extracted parts of the document. According to the information, the policy number of Yagnya is **92000034230400000103**.\"}\n",
            "does any parasites are seen in blood reports of yagnya deshpande?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query': 'does any parasites are seen in blood reports of yagnya deshpande?', 'result': 'Based on the report, I can tell you that according to the Peripheral blood Smear (PBS), Parasites were NOT seen. The report specifically states \"Parasites : Not seen\" under the PBS section.'}\n",
            "Is viral gastro enteritis and hepatitis correct for yagnya?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'Is viral gastro enteritis and hepatitis correct for yagnya?', 'result': \"Hello! I'm happy to help you with your query.\\n\\nAccording to the discharge summary, Miss. Yagnya Deshpande was diagnosed with Viral Gastro-enteritis with Hepatitis during her hospitalization at Suraj Hospital. \\n\\nSo, to answer your question, yes, Viral Gastro-enteritis and Hepatitis were indeed the correct diagnoses for Yagnya.\"}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-56ab0f873068>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mqu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mqu\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SkPb_CtCNE_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}